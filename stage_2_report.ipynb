{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Stage2 機械学習\n",
    "## 機械学習概要\n",
    "## 線形回帰モデル\n",
    "## 非線形回帰モデル\n",
    "## ロジスティック回帰モデル\n",
    "## 主成分分析\n",
    "## アルゴリズム\n",
    "## サポートベクターマシン"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 機械学習概要"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- 機械学習\n",
    "<br>\n",
    "タスクをプログラムで実行する際の性能を、データを与えることで改善させる\n",
    "<br>\n",
    "人は学習の仕方をプログラミングする\n",
    "- モデリングプロセス\n",
    "  1. 問題設定\n",
    "  1. データ選定\n",
    "  1. データの前処理\n",
    "  1. 機械学習モデルの選定\n",
    "  1. モデルの学習(パラメータ推定)\n",
    "  1. モデルの評価\n",
    "- 機械学習タスク\n",
    "  - 教師あり学習\n",
    "  <br>\n",
    "  学習時に正解データを与える\n",
    "  <br>\n",
    "  数値(連続値)を正解とする予測と、ラベル(離散値)を正解とする分類がある\n",
    "  - 教師なし学習\n",
    "  <br>\n",
    "  学習時に正解データを与えない\n",
    "  <br>\n",
    "  入力データをグループ分けするクラスタリングと、入力データを圧縮する次元削減がある\n",
    "- データの分割\n",
    "<br>\n",
    "機械学習モデルの学習時にはデータを学習用(モデルの学習)と検証用(モデルの精度を検証)に分割する\n",
    "<br>\n",
    "データを分割することで汎化性能(未知のデータに対する性能)を測定できる"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 線形回帰モデル"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### まとめ\n",
    "- 線形\n",
    "<br>\n",
    "入力と出力が超平面の関係にある(比例の拡張)\n",
    "<br>\n",
    "$\\begin{align}\n",
    "y &= \\sum_{i = 0}^{n - 1} a_i x_i (x_0 = 1) \\nonumber \\\\\n",
    " &= \\mathbb{a}^T \\mathbb{x} \\nonumber\n",
    "\\end{align}$\n",
    "- 回帰問題\n",
    "<br>\n",
    "ある入力(離散あるいは連続値)から出力を予測する問題\n",
    "<br>\n",
    "入力と出力の関係が線形ならば線形回帰、そうでなければ非線形回帰\n",
    "<br>\n",
    "入力(説明変数または特徴量)をm次元ベクトル $\\mathbb{x}$ 、出力(目的変数)をスカラー値 $y$ で表す\n",
    "- 線形回帰モデル\n",
    "<br>\n",
    "回帰問題に対する機械学習モデルの1つ\n",
    "<br>\n",
    "入力とパラメータの線形結合を出力\n",
    "<br>\n",
    "出力は線形結合+誤差と仮定\n",
    "  - パラメータ $\\mathbb{w} \\in \\mathbb{R}^n$\n",
    "  - 線形結合 $\\hat{y} = \\mathbb{w}^T x + w_0$\n",
    "  - 教師データ $\\{(\\mathbb{x}_i, y_i) \\mid i=1, \\ldots, n\\}$\n",
    "- 線形回帰モデルの学習\n",
    "<br>\n",
    "最小二乗法(学習データの平均二乗誤差の最小化)でパラメータを学習\n",
    "<br>\n",
    "$\\hat{\\mathbb{w}} = \\arg \\min_{\\mathbb{w} \\in \\mathbb{R}^{m + 1}} \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} \\left(\\hat{y}_{i}^{(\\text{train})} - y_{i}^{(\\text{train})}\\right)^2$\n",
    "<br>\n",
    "外れ値に弱い"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 実装演習\n",
    "- np_regression.ipynb\n",
    "<br>\n",
    "単回帰・多項式回帰・重回帰のコードを実行した\n",
    "<br>\n",
    "単回帰の精度は高いように見えたが、重回帰(3変数)の結果は正解から大きく外れていた\n",
    "<br>\n",
    "重回帰ではデータが10件と少ないため、精度が悪いと考えられる\n",
    "<br>\n",
    "以下は重回帰の結果である\n",
    "    \n",
    "    w0_true:   1.0   w0_estimated: -0.19\n",
    "    w1_true:   0.5   w1_estimated: 1.3e+01\n",
    "    w2_true:   2.0   w2_estimated: -3.8e+01\n",
    "    w3_true:   1.0   w3_estimated: 2.5e+01\n",
    "- skl_regression.ipynb\n",
    "<br>\n",
    "Boston Housing Dataに対して単回帰・重回帰(2変数)のコードを実行した\n",
    "<br>\n",
    "データに対してかなり単純なモデルであるため、予測精度はよくない\n",
    "<br>\n",
    "以下は単回帰の結果である\n",
    "<br>\n",
    "<img src=\"stage_2_linear.png\">\n",
    "- まとめ\n",
    "線形回帰は複雑なデータに対して精度は高くならない\n",
    "<br>\n",
    "一方でモデルの中身が単純であり、パラメータから入力と出力の関係が読み取りやすい"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}