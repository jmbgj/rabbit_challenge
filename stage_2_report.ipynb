{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Stage2 機械学習\n",
    "## 機械学習概要\n",
    "## 線形回帰モデル\n",
    "## 非線形回帰モデル\n",
    "## ロジスティック回帰モデル\n",
    "## 主成分分析\n",
    "## k近傍法(kNN)\n",
    "## k-平均法(k-means)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 機械学習概要"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- 機械学習\n",
    "<br>\n",
    "タスクをプログラムで実行する際の性能を、データを与えることで改善させる\n",
    "<br>\n",
    "人は学習の仕方をプログラミングする\n",
    "- モデリングプロセス\n",
    "  1. 問題設定\n",
    "  1. データ選定\n",
    "  1. データの前処理\n",
    "  1. 機械学習モデルの選定\n",
    "  1. モデルの学習(パラメータ推定)\n",
    "  1. モデルの評価\n",
    "- 機械学習タスク\n",
    "  - 教師あり学習\n",
    "  <br>\n",
    "  学習時に正解データを与える\n",
    "  <br>\n",
    "  数値(連続値)を正解とする予測と、ラベル(離散値)を正解とする分類がある\n",
    "  - 教師なし学習\n",
    "  <br>\n",
    "  学習時に正解データを与えない\n",
    "  <br>\n",
    "  入力データをグループ分けするクラスタリングと、入力データを圧縮する次元削減がある\n",
    "- データの分割\n",
    "<br>\n",
    "機械学習モデルの学習時にはデータを学習用(モデルの学習)と検証用(モデルの精度を検証)に分割する\n",
    "<br>\n",
    "データを分割することで汎化性能(未知のデータに対する性能)を測定できる\n",
    "<br>\n",
    "ホールドアウト法やクロスバリデーションなどの方法がある"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 線形回帰モデル"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### まとめ\n",
    "- 線形\n",
    "<br>\n",
    "入力と出力が超平面の関係にある(比例の拡張)\n",
    "<br>\n",
    "$\\begin{align}\n",
    "y &= \\sum_{i = 0}^{n - 1} a_i x_i (x_0 = 1) \\nonumber \\\\\n",
    " &= \\mathbb{a}^T \\mathbb{x} \\nonumber\n",
    "\\end{align}$\n",
    "- 回帰問題\n",
    "<br>\n",
    "ある入力(離散あるいは連続値)から出力を予測する問題\n",
    "<br>\n",
    "入力と出力の関係が線形ならば線形回帰、そうでなければ非線形回帰\n",
    "<br>\n",
    "入力(説明変数または特徴量)をm次元ベクトル $\\mathbb{x}$ 、出力(目的変数)をスカラー値 $y$ で表す\n",
    "- 線形回帰モデル\n",
    "<br>\n",
    "回帰問題に対する機械学習モデルの1つ\n",
    "<br>\n",
    "入力とパラメータの線形結合を出力\n",
    "<br>\n",
    "出力は線形結合+誤差と仮定\n",
    "  - パラメータ $\\mathbb{w} \\in \\mathbb{R}^n$\n",
    "  - 線形結合 $\\hat{y} = \\mathbb{w}^T x + w_0$\n",
    "  - 教師データ $\\{(\\mathbb{x}_i, y_i) \\mid i=1, \\ldots, n\\}$\n",
    "- 線形回帰モデルの学習\n",
    "<br>\n",
    "最小二乗法(学習データの平均二乗誤差の最小化)でパラメータを学習\n",
    "<br>\n",
    "$\\hat{\\mathbb{w}} = \\arg \\min_{\\mathbb{w} \\in \\mathbb{R}^{m + 1}} \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} \\left(\\hat{y}_{i}^{(\\text{train})} - y_{i}^{(\\text{train})}\\right)^2$\n",
    "<br>\n",
    "外れ値に弱い"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 実装演習\n",
    "- np_regression.ipynb\n",
    "<br>\n",
    "単回帰・多項式回帰・重回帰のコードを実行した\n",
    "<br>\n",
    "単回帰の精度は高いように見えたが、重回帰(3変数)の結果は正解から大きく外れていた\n",
    "<br>\n",
    "重回帰ではデータが10件と少ないため、精度が悪いと考えられる\n",
    "<br>\n",
    "以下は重回帰の結果である\n",
    "```\n",
    "    w0_true:   1.0   w0_estimated: -0.19\n",
    "    w1_true:   0.5   w1_estimated: 1.3e+01\n",
    "    w2_true:   2.0   w2_estimated: -3.8e+01\n",
    "    w3_true:   1.0   w3_estimated: 2.5e+01\n",
    "```\n",
    "- skl_regression.ipynb\n",
    "<br>\n",
    "Boston Housing Dataに対して単回帰・重回帰(2変数)のコードを実行した\n",
    "<br>\n",
    "データに対してかなり単純なモデルであるため、予測精度はよくない\n",
    "<br>\n",
    "以下は単回帰の結果である\n",
    "<br>\n",
    "<img src=\"stage_2_linear.png\">\n",
    "- まとめ\n",
    "線形回帰は複雑なデータに対して精度は高くならない\n",
    "<br>\n",
    "一方でモデルの中身が単純であり、パラメータから入力と出力の関係が読み取りやすい"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 非線形回帰モデル"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### まとめ\n",
    "- 基底展開法\n",
    "<br>\n",
    "基底展開法(非線形回帰モデル)では、線形回帰の $x$ の代わりに $\\phi (x)$ を用いる\n",
    "<br>\n",
    "例：$y = w_0 + w_1 x + w_2 x^2 + w_3 x_3$\n",
    "<br>\n",
    "入力については非線形だが、パラメータについては非線形\n",
    "<br>\n",
    "- 基底関数 $\\phi (x)$\n",
    "<br>\n",
    "多項式関数 $\\phi_j (x) = x^j$\n",
    "<br>\n",
    "ガウス型基底関数 $\\phi_j (x) = \\exp \\left\\{\\frac{(x - \\mu_j)^2}{2 h_j}\\right\\}$\n",
    "- 基底展開法の学習\n",
    "<br>\n",
    "入力を $x$ から $\\phi (x)$ に置き換えることで、線形回帰モデルと同様に学習可能\n",
    "- 未学習と過学習\n",
    "  - 未学習\n",
    "  <br>\n",
    "  学習データに対して、誤差が大きい\n",
    "  <br>\n",
    "  より表現力の高い(項が多いなどの)モデルを利用する必要がある\n",
    "  - 過学習\n",
    "  <br>\n",
    "  学習データに対して誤差は小さいが、テストデータに対して誤差が大きい\n",
    "  <br>\n",
    "  学習データを増やす、モデルの表現力を下げる(項を減らす、正則化を利用)などで対策\n",
    "- 正則化(罰則化)\n",
    "<br>\n",
    "モデルが複雑になると値が大きくなる項(正則化項)を誤差に足して学習\n",
    "<br>\n",
    "L2ノルムやL1ノルムなどを正則化項に利用する"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 実装演習\n",
    "- skl_nonlinear regression.ipynb\n",
    "<br>\n",
    "非線形な形で生成されたデータに対して、以下の機械学習モデルを実行した\n",
    "データが単純なため、非線形回帰では精度が高くなりやすいが、ハイパーパラメータの調整が必要\n",
    "  - 線形回帰\n",
    "  <br>\n",
    "  予測が全くうまくいっていない\n",
    "  <br>\n",
    "  <img src=\"stage_2_nonlinear_linear.png\">\n",
    "  - ガウス型基底関数+L2ノルム(非線形回帰)\n",
    "  <br>\n",
    "  図のように多くの関数の線形結合で回帰を行っている\n",
    "  <br>\n",
    "  予測がうまくいっているように見える\n",
    "  <br>\n",
    "  <img src=\"stage_2_nonlinear_kernelRidge.png\">\n",
    "  - ガウス型基底関数+L1ノルム(非線形回帰)\n",
    "  <br>\n",
    "  L1ノルムの係数により大きく結果が変わる\n",
    "  <br>\n",
    "  図は $\\alpha = 0.01$ の場合\n",
    "  <br>\n",
    "  $\\alpha$ が大きいと予測値がほぼ0になる(パラメータが0になるため))\n",
    "  <br>\n",
    "  <img src=\"stage_2_nonlinear_kernelLasso.png\">\n",
    "  - 多項式回帰(非線形回帰)\n",
    "  <br>\n",
    "  1次から10次の多項式で回帰\n",
    "  <br>\n",
    "  図から次数によって回帰曲線が複雑になることがわかる\n",
    "  <br>\n",
    "  適切な次数での予測はうまくいっている\n",
    "  <br>\n",
    "  <img src=\"stage_2_nonlinear_polynomial.png\">\n",
    "  - サポートベクター回帰(非線形回帰)\n",
    "  <br>\n",
    "  ハイパーパラメータにより予測精度が大きく異なる\n",
    "  <br>\n",
    "  ハイパーパラメータの調整が適切ならば、予測精度は高くなる\n",
    "  <br>\n",
    "  <img src=\"stage_2_nonlinear_SVR.png\">\n",
    "  - 深層学習\n",
    "  <br>\n",
    "  精度は他の非線形回帰程度に高くなるが、学習時間が大きくなる\n",
    "  <br>\n",
    "  単純なデータであるため、あまり利用すべきではないと考えられる\n",
    "  <br>\n",
    "  <img src=\"stage_2_nonlinear_DL.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ロジスティック回帰モデル"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### まとめ\n",
    "- 分類問題\n",
    "<br>\n",
    "目的変数がクラス(離散値)である問題\n",
    "  - 説明変数 $\\mathbb{x} = (x_1, x_2, \\ldots, x_m)^T \\in R^m$\n",
    "  - 目的変数 $y \\in \\{0, 1\\}$\n",
    "  - 教師データ $\\{(\\mathbb{x}_i, y) \\mid i = 1, \\ldots, n\\}$\n",
    "- 分類問題に対するアプローチ\n",
    "<br>\n",
    "ロジスティック回帰は識別的アプローチ\n",
    "  - 識別的アプローチ\n",
    "  <br>\n",
    "  $p (C_k \\mid  \\mathbb{x})$ を直接モデル化\n",
    "  <br>\n",
    "  識別関数 $f$ を構成する場合もある($f(\\mathbb{x})>0$ ならば $C = 1$ など)\n",
    "  - 生成的アプローチ\n",
    "  <br>\n",
    "  $p (C_k)$ を $p (\\mathbb{x} \\mid C_k)$ をモデル化し、ベイズ則で $p (C_k \\mid \\mathbb{x})$ を求める\n",
    "- ロジスティック回帰モデル\n",
    "<br>\n",
    "分類問題を解くためのモデル\n",
    "<br>\n",
    "$\\mathbb{x}^T \\mathbb{w}$ を $[0, 1]$ に変換(シグモイド関数 $\\sigma$ を利用)し、 $y$ と対応させる\n",
    "<br>\n",
    "$P(Y = 1 \\mid \\mathbb{x}) = \\sigma (w_0 + w_1 x_1 + \\cdots + w_m x_m)$\n",
    "- シグモイド関数\n",
    "<br>\n",
    "入力が任意の実数で出力は0～1の値\n",
    "<br>\n",
    "確率を表現するのに利用される\n",
    "<br>\n",
    "シグモイド関数の微分はシグモイド関数で表される(計算しやすい)\n",
    "- ロジスティック回帰モデルの学習\n",
    "<br>\n",
    "ロジスティック回帰モデルではベルヌーイ分布を利用し、パラメータを最尤推定している\n",
    "<br>\n",
    "最尤推定：尤度関数(パラメータが固定のときに与えられたデータが得られる確率)が最大となるパラメータを推定\n",
    "<br>\n",
    "ロジスティック回帰モデルの最尤推定は解析的に解くのが難しいため、勾配降下法(逐次的な探索)または確率的勾配降下法で解く\n",
    "- 分類問題の性能指標\n",
    "  混同行列(予測クラスと実際のクラスの組み合わせごとに個数をカウントし、 $2 \\times 2$ の行列で表す)などを利用"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 実装演習\n",
    "- skl_logistic_regression.ipynb\n",
    "<br>\n",
    "Titanic Dataの生死推定をロジスティック回帰で行った\n",
    "  - 1変数(チケット価格)利用の場合\n",
    "  <br>\n",
    "  チケット価格が高いほど生存と推定している\n",
    "  <br>\n",
    "  また出力結果とシグモイド関数の関係がよく見える\n",
    "  <br>\n",
    "  <img src=\"stage_2_logistic_1.png\">\n",
    "  <br>\n",
    "  混同行列を見ると、ほとんど死亡と推定していることがわかる(実際の値もほとんどが死亡)\n",
    "  <br>\n",
    "  <img src=\"stage_2_logistic_confusion1.png\">\n",
    "  - 2変数利用の場合\n",
    "  <br>\n",
    "  分類境界はデータの傾向をつかんでいるように見える\n",
    "  <br>\n",
    "  <img src=\"stage_2_logistic_2.png\">\n",
    "  <br>\n",
    "  混同行列からは、1変数の場合より精度が高くなっていることがわかる\n",
    "  <br>\n",
    "  <img src=\"stage_2_logistic_confusion2.png\">\n",
    "  - 性別ごと\n",
    "  <br>\n",
    "  性別ごとにロジスティック回帰を行った\n",
    "  <br>\n",
    "  結果から、性別によって年齢と生死の関係が違うことがわかる\n",
    "  <br>\n",
    "  <img src=\"stage_2_logistic_faceted.png\">\n",
    "- np_logistic_regression.ipynb\n",
    "<br>\n",
    "ランダムに生成したデータに対してロジスティック回帰を行った\n",
    "<br>\n",
    "機械学習のパッケージを利用していないため、学習アルゴリズムの実装がよく分かった\n",
    "<br>\n",
    "<img src=stage_2_logistic_np.png>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 主成分分析"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### まとめ\n",
    "- 主成分分析\n",
    "<br>\n",
    "多変量データを圧縮(入力データの線形変換を少数利用)する手法\n",
    "<br>\n",
    "可視化や分析を扱いやすくするために利用\n",
    "- 主成分分析の学習\n",
    "<br>\n",
    "線形返還後の変数の分散が最大(情報が多い)となるようにパラメータを学習\n",
    "<br>\n",
    "ラグランジュの未定乗数法を利用して解く"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 実装演習\n",
    "- skl_pca.ipynb\n",
    "<br>\n",
    "がんのデータに対して主成分分析の有無により、ロジスティック回帰の分類精度の変化を観察した\n",
    "<br>\n",
    "主成分分析なしですべての変数を利用して分類すると、検証データの正解率が97%だった\n",
    "<br>\n",
    "一方、主成分分析で2変数に圧縮してから分類すると、図の結果になった\n",
    "<br>\n",
    "使用する変数の数が大きく異なるが、分類精度があまり悪化していないことがわかる\n",
    "<br>\n",
    "すなわち、元のデータが2変数でうまく圧縮されている\n",
    "<br>\n",
    "<img src=\"stage_2_PCA.png\">\n",
    "- np_pca.ipynb\n",
    "<br>\n",
    "ランダムに相関のあるデータを生成し、主成分分析を行った\n",
    "<br>\n",
    "図から主成分分析が分散を考慮してデータを圧縮している様子がわかる\n",
    "<br>\n",
    "また2つの主成分が直交していることもわかる\n",
    "<br>\n",
    "他に固有ベクトルと主成分の関係を観察した\n",
    "<br>\n",
    "<img src=\"stage_2_PCA_np.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## k近傍法(kNN)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### まとめ\n",
    "- k近傍法\n",
    "<br>\n",
    "分類問題のための機械学習手法\n",
    "<br>\n",
    "最近傍のデータをk個探して、最頻値のクラスを出力\n",
    "<br>\n",
    "kを変化させると結果が変わる(適切なパラメータを選択する必要がある)\n",
    "<br>\n",
    "kを大きくすると決定境界が滑らかになる"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 実装演習\n",
    "- np_knn_ipynb\n",
    "<br>\n",
    "ランダムに生成したデータに対して、k近傍法でクラスタリングを行った\n",
    "<br>\n",
    "コードを実行することでk近傍法の学習とはデータを記憶することでしかないことを実感した\n",
    "<br>\n",
    "またkの値を大きくすると境界線が滑らかになることを観察した\n",
    "<br>\n",
    "図は $k = 3$ と $k = 11$ の場合だが、 $k = 11$ の場合のほうが境界が滑らかになっていることがわかる\n",
    "<br>\n",
    "<img src=\"stage_2_kNN.png\">\n",
    "<img src=\"stage_2_kNN_11.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## k-平均法(k-means)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### まとめ\n",
    "- k-平均法\n",
    "<br>\n",
    "クラスタリング(教師なし学習)の手法\n",
    "<br>\n",
    "クラスタリング：与えられたデータに対して、特徴の似ているもの同士をグループ化\n",
    "<br>\n",
    "初期値を変えるとクラスタリング結果が変わる(k-平均法の改良によって改善)\n",
    "- k-平均法のアルゴリズム\n",
    "  1. 各クラスタ中心の初期値を設定\n",
    "  1. 各データ点に対して各クラスタ中心との距離を計算して、最も距離が近いクラスタを割り当て\n",
    "  1. 各クラスタの平均ベクトル(中心)を計算\n",
    "  1. 収束するまで2、3を繰り返す"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 実装演習\n",
    "- skl_kmeans.ipynb\n",
    "<br>\n",
    "Wine Datasetに対してk-平均法によってクラスタリングを行った\n",
    "<br>\n",
    "クラスタリング結果とデータセット中のクラス(クラスタリングには使用していない)がある程度対応した\n",
    "<br>\n",
    "ここから、このデータでは入力と出力の対応関係があることが読み取れる\n",
    "    \n",
    "            class_0  class_1  class_2\n",
    "    labels\n",
    "         0        0       50       19\n",
    "         1       46        1        0\n",
    "         2       13       20       29\n",
    "- np_kmeans.ipynb\n",
    "<br>\n",
    "ランダムに生成したデータに対してk-平均法でクラスタリングを行った\n",
    "<br>\n",
    "単純なデータであるため、うまくクラスタリングできた\n",
    "<br>\n",
    "パッケージを使用せずに実装したため、k-平均法のアルゴリズムがよく理解できた\n",
    "<br>\n",
    "<img src=\"stage_2_kmeans.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}